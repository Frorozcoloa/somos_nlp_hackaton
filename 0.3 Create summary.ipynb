{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from segtok.segmenter import split_single\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text, split_by_comma=False):\n",
    "    \"\"\"\n",
    "    Esta función divide una cadena en una lista de oraciones.\n",
    "    Nos basamos en la librería segtok para usar esta funcionalidad.\n",
    "    Parámetros\n",
    "    ----------\n",
    "    text : str\n",
    "        Cadena a dividir.\n",
    "    split_by_comma : bool, optional\n",
    "        Si es True, las cadenas también se dividen por comas. El valor por defecto\n",
    "        es False.\n",
    "    Devuelve\n",
    "    -------\n",
    "    list of str\n",
    "        Lista de oraciones.\n",
    "    \"\"\"\n",
    "    sentences = split_single(text)\n",
    "    if split_by_comma:\n",
    "        sentences = [sentence.split(\", \") for sentence in sentences]\n",
    "        sentences = [item for sublist in sentences for item in sublist]\n",
    "    return sentences\n",
    "\n",
    "def process_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Procesa el texto para utilizarlo en un modelo.\n",
    "    En particular, elimina saltos de línea, tabulaciones y\n",
    "    espacios en blanco repetidos.\n",
    "    Parámetros\n",
    "    ----------\n",
    "    text : str\n",
    "        Cadena a procesar.\n",
    "    Devuelve\n",
    "    -------\n",
    "    str\n",
    "        Cadena procesada.\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    text = text.strip()\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"\"\"El 8 de julio de 2021 el Tribunal de Apelación de Rumanía confirmó la sentencia anterior del Tribunal de Constanța y dictaminó que el alcalde de Eforie y la Unidad Territorial Administrativa de Eforie deben pagar una suma de aproximadamente 36.000 € a cada persona romaní desalojada en 2013, así como proporcionar vivienda social para cada familia. Hay doce personas representadas en el caso, lo que significa que el coste total para las autoridades de Eforie (menos los costes de vivienda) será de aproximadamente 432.000 €. El caso fue presentado por el Centro Europeo de Derechos de los Romaníes (ERRC) y RomaJust El desalojo se produjo el 27 de septiembre de 2013 y tuvo como objetivo a una comunidad gitana que vivía en la calle Agricole en unas 22 casas, desde hacía 40 años. Fue llevado a cabo por 80 policías acompañados por trabajadores del municipio y excavadoras, bajo la supervisión directa del teniente de alcalde de Eforie que asistió al desalojo. Más de 100 personas, incluidos 55 niños y niñas, quedaron sin hogar cuando sus hogares fueron destruidos sin consulta ni provisión de vivienda alternativa adecuada. Los medios locales informaron que se escuchó al teniente de alcalde amenazar a los romaníes que se resistían, diciendo “si no salen, los vamos a matar aquí”. \n",
    "En los días siguientes, las personas desalojadas tuvieron que vivir a la intemperie en albergues temporales hasta que algunos pudieron refugiarse en un edificio escolar abandonado sin ventanas ni electricidad. Algunas de estas personas fueron desalojadas por segunda vez en julio de 2014 por el teniente de alcalde y reubicadas en contenedores fuera de la ciudad. Estos contenedores eran demasiado pequeños para albergar a todos los miembros de las familias y tenían un acceso inadecuado a las instalaciones básicas. El resto de las familias no recibieron alojamiento de ningún tipo. Después de que el Tribunal Europeo de Derechos Humanos detuviera otro intento de desalojo a las familias gitanas que vivían en los contenedores en marzo de 2016, el desalojo original finalmente se consideró ilegal y discriminatorio el 1 de junio de 2016.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = process_text(TEXT)\n",
    "sentences = split_into_sentences(text, split_by_comma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logging' from 'huggingface_hub' (c:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_login\n\u001b[0;32m      3\u001b[0m notebook_login()\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\__init__.py:278\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m attr_to_modules:\n\u001b[0;32m    277\u001b[0m     submod_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpackage_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mattr_to_modules[name]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 278\u001b[0m     submod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(submod_path)\n\u001b[0;32m    279\u001b[0m     attr \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(submod, name)\n\u001b[0;32m    281\u001b[0m     \u001b[39m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[39m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\_login.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Optional\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcommands\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_cli_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ANSI\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcommands\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdelete_cache\u001b[39;00m \u001b[39mimport\u001b[39;00m _ask_for_confirmation_no_tui\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhf_api\u001b[39;00m \u001b[39mimport\u001b[39;00m HfApi\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     HfFolder,\n\u001b[0;32m     25\u001b[0m     is_google_colab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     unset_git_credential,\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\commands\\delete_cache.py:64\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtempfile\u001b[39;00m \u001b[39mimport\u001b[39;00m mkstemp\n\u001b[0;32m     62\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Iterable, List, Optional, Union\n\u001b[1;32m---> 64\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m CachedRepoInfo, CachedRevisionInfo, HFCacheInfo, scan_cache_dir\n\u001b[0;32m     65\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseHuggingfaceCLICommand\n\u001b[0;32m     66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_cli_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ANSI\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\utils\\__init__.py:94\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_validators\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     82\u001b[0m     HFValidationError,\n\u001b[0;32m     83\u001b[0m     smoothly_deprecate_use_auth_token,\n\u001b[0;32m     84\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     85\u001b[0m     validate_repo_id,\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     88\u001b[0m     are_progress_bars_disabled,\n\u001b[0;32m     89\u001b[0m     disable_progress_bars,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m     tqdm_stream_file,\n\u001b[0;32m     93\u001b[0m )\n\u001b[1;32m---> 94\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_telemetry\u001b[39;00m \u001b[39mimport\u001b[39;00m send_telemetry\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\utils\\_telemetry.py:8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m quote\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m constants, logging\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m build_hf_headers, hf_raise_for_status\n\u001b[0;32m     12\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'logging' from 'huggingface_hub' (c:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logging' from 'huggingface_hub' (c:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizerFast, EncoderDecoderModel\n\u001b[0;32m      3\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m ckpt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmrm8488/bert2bert_shared-spanish-finetuned-summarization\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     logging,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\dependency_versions_check.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     20\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\utils\\__init__.py:30\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     24\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     ContextManagers,\n\u001b[0;32m     32\u001b[0m     ExplicitEnum,\n\u001b[0;32m     33\u001b[0m     ModelOutput,\n\u001b[0;32m     34\u001b[0m     PaddingStrategy,\n\u001b[0;32m     35\u001b[0m     TensorType,\n\u001b[0;32m     36\u001b[0m     cached_property,\n\u001b[0;32m     37\u001b[0m     can_return_loss,\n\u001b[0;32m     38\u001b[0m     expand_dims,\n\u001b[0;32m     39\u001b[0m     find_labels,\n\u001b[0;32m     40\u001b[0m     flatten_dict,\n\u001b[0;32m     41\u001b[0m     is_jax_tensor,\n\u001b[0;32m     42\u001b[0m     is_numpy_array,\n\u001b[0;32m     43\u001b[0m     is_tensor,\n\u001b[0;32m     44\u001b[0m     is_tf_tensor,\n\u001b[0;32m     45\u001b[0m     is_torch_device,\n\u001b[0;32m     46\u001b[0m     is_torch_dtype,\n\u001b[0;32m     47\u001b[0m     is_torch_tensor,\n\u001b[0;32m     48\u001b[0m     reshape,\n\u001b[0;32m     49\u001b[0m     squeeze,\n\u001b[0;32m     50\u001b[0m     tensor_size,\n\u001b[0;32m     51\u001b[0m     to_numpy,\n\u001b[0;32m     52\u001b[0m     to_py_obj,\n\u001b[0;32m     53\u001b[0m     transpose,\n\u001b[0;32m     54\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     58\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     send_example_telemetry,\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     88\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m     torch_version,\n\u001b[0;32m    167\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\utils\\generic.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, ContextManager, List, Tuple\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_flax_available():\n\u001b[0;32m     33\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\utils\\import_utils.py:32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m importlib_metadata\n\u001b[0;32m     36\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\transformers\\utils\\logging.py:35\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     CRITICAL,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     DEBUG,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     WARNING,  \u001b[39m# NOQA\u001b[39;00m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m---> 35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhf_hub_utils\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m auto \u001b[39mas\u001b[39;00m tqdm_lib\n\u001b[0;32m     39\u001b[0m _lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\utils\\__init__.py:94\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_validators\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     82\u001b[0m     HFValidationError,\n\u001b[0;32m     83\u001b[0m     smoothly_deprecate_use_auth_token,\n\u001b[0;32m     84\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     85\u001b[0m     validate_repo_id,\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     88\u001b[0m     are_progress_bars_disabled,\n\u001b[0;32m     89\u001b[0m     disable_progress_bars,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m     tqdm_stream_file,\n\u001b[0;32m     93\u001b[0m )\n\u001b[1;32m---> 94\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_telemetry\u001b[39;00m \u001b[39mimport\u001b[39;00m send_telemetry\n",
      "File \u001b[1;32mc:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\utils\\_telemetry.py:8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m quote\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m constants, logging\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m build_hf_headers, hf_raise_for_status\n\u001b[0;32m     12\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'logging' from 'huggingface_hub' (c:\\Users\\froro\\OneDrive\\Escritorio\\Hackaton\\.nlp\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt = 'mrm8488/bert2bert_shared-spanish-finetuned-summarization'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)\n",
    "model = EncoderDecoderModel.from_pretrained(ckpt).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
